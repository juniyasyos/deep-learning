{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94aeecc1",
   "metadata": {},
   "source": [
    "# Praktikum Deep Learning — Transfer Learning (Pengantar & Demo Konsep)\n",
    "\n",
    "_Notebook ini memandu kamu memahami konsep inti transfer learning sebelum terjun ke studi kasus aktual. Gunakan sebagai pijakan awal: jalankan sel satu per satu, catat pengamatan, dan refleksikan apa yang terjadi._\n",
    "\n",
    "> Tips: aktifkan menu **View → Table of Contents** di JupyterLab supaya navigasi antar bagian lebih mudah.\n",
    "\n",
    "---\n",
    "\n",
    "**Profil Modul**\n",
    "- **Untuk siapa?** Mahasiswa yang sudah nyaman dengan CNN dasar dan Python.\n",
    "- **Durasi saran:** 2 x 50 menit (teori interaktif 40 menit, demo terarah 35 menit, refleksi 25 menit).\n",
    "- **Peran Notebook:** panduan belajar mandiri sekaligus skrip demonstrasi yang dapat kamu ulangi setelah sesi.\n",
    "\n",
    "**Mengapa Modul Ini Penting**\n",
    "- Kamu akan melihat langsung bagaimana reuse model pretrained menghemat waktu eksperimen.\n",
    "- Transfer learning membuatmu melangkah lebih jauh dengan data terbatas—ibarat sudah bisa berjalan, lalu belajar berlari tanpa harus tumbuh dari bayi lagi.\n",
    "- Bayangkan pemain biola yang beralih ke pemrograman: ia tidak mengulang belajar ritme dari nol, melainkan memindahkan sensitivitas tempo ke logika kode. Transfer learning bekerja dengan cara serupa, membawa keterampilan lama ke domain baru.\n",
    "\n",
    "**Apa yang Akan Kamu Lakukan**\n",
    "1. Menyegarkan kembali motivasi transfer learning dan menautkannya dengan pengalaman belajarmu.\n",
    "2. Menjalankan eksperimen terstruktur: konfigurasi, dataset dummy, dan modifikasi backbone.\n",
    "3. Menganalisis metrik dan mengaitkannya dengan strategi fine-tuning.\n",
    "4. Menyusun ide perluasan ringan untuk eksplorasi pribadi.\n",
    "\n",
    "**Prasyarat Teknis**\n",
    "- Memahami supervised learning, metrik akurasi, dan konsep overfitting.\n",
    "- Familiar dengan komponen PyTorch dasar (`DataLoader`, `nn.Module`, training loop).\n",
    "- Sudah memasang dependensi pada `requirements.txt`.\n",
    "\n",
    "**Hasil Belajar yang Diharapkan**\n",
    "- Catatan refleksi kapan memilih freeze vs fine-tuning.\n",
    "- Screenshot atau langkah analisis plot loss-akurasi di setiap tahap.\n",
    "- Draft ide adaptasi model untuk dataset pilihanmu sendiri.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9144e996",
   "metadata": {},
   "source": [
    "## Navigasi & Cara Menggunakan Notebook\n",
    "\n",
    "Ikuti alur berikut agar pengalaman latihan terasa ringan namun efektif:\n",
    "1. **Baca cepat bagian A–C.** Catat tujuan utama dan ringkasan teori supaya kamu tahu apa yang sedang dicari.\n",
    "2. **Jalankan blok kode secara berurutan mulai dari D.** Setiap blok sudah diberi log sehingga kamu tahu status terbaru.\n",
    "3. **Perhatikan output di bagian F dan G.** Di sana kamu akan melihat jumlah sampel subset serta banyaknya parameter yang benar-benar dilatih.\n",
    "4. **Amati log training di bagian H.** Log `[feature_extraction]` dan `[fine_tuning]` menunjukkan progress epoch tanpa perlu buka plot terlebih dulu.\n",
    "5. **Gunakan bagian I–N untuk refleksi.** Plot, checklist, dan glosarium membantu mengikat hasil eksperimen ke konsep teori.\n",
    "\n",
    "> Tips cepat: jika waktu sangat terbatas, jalankan hanya hingga plot pada bagian I; sisanya bisa dibaca untuk pemahaman tanpa eksekusi ulang.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e2e197",
   "metadata": {},
   "source": [
    "## A. Judul & Tujuan Pembelajaran\n",
    "\n",
    "Gunakan bagian ini untuk menyelaraskan harapan. Bacalah tujuan berikut, lalu tuliskan (misalnya di jurnal atau catatan digital) dua pertanyaan yang ingin kamu jawab setelah praktikum selesai.\n",
    "\n",
    "**Learning Objectives**\n",
    "- Memahami konsep dan motivasi Transfer Learning (hemat data, waktu, serta sumber daya komputasi) dan posisinya dalam pipeline deep learning modern.\n",
    "- Menjelaskan kelebihan utama pendekatan ini: efisiensi training, kebutuhan data lebih sedikit, performa stabil, dan mitigasi overfitting.\n",
    "- Mengidentifikasi variasi Transfer Learning (Inductive, Transductive, Unsupervised) serta kapan masing-masing cocok dipakai.\n",
    "- Membedakan mode feature extraction (freeze) vs fine-tuning penuh atau parsial, termasuk pengaruhnya pada jumlah parameter yang di-update.\n",
    "- Mengaplikasikan konfigurasi PyTorch untuk memuat backbone pretrained dan menyesuaikan classifier head.\n",
    "\n",
    "**Setelah Selesai Kamu Seharusnya Bisa**\n",
    "- Menyebutkan minimal dua alasan transfer learning relevan untuk dataset aktual.\n",
    "- Menganalisis kapan harus membuka layer tambahan ketika domain target jauh dari domain sumber.\n",
    "- Memodifikasi hyperparameter dasar (learning rate, `freeze_until`) dan menuliskan implikasinya.\n",
    "\n",
    "**Pemanasan Cepat**\n",
    "- Bayangkan proses belajar berjalan: kamu tidak mengulang dari merangkak setiap kali belajar olahraga baru. Transfer learning bekerja dengan prinsip serupa. Catat analogi versimu sendiri di catatan praktikum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef3d316",
   "metadata": {},
   "source": [
    "## B. Recall & Icebreaker\n",
    "\n",
    "Luangkan 10 menit untuk kembali ke pengalamanmu sendiri. Jika belajar berkelompok, diskusikan jawaban; jika mandiri, tuliskan poin-poin penting.\n",
    "\n",
    "1. Apa tantangan melatih CNN dari nol ketika dataset kecil? Hubungkan dengan pengalamanmu memulai dari hal yang benar-benar baru tanpa referensi (ibarat belajar berjalan tanpa contoh).\n",
    "2. Mengapa reuse pengetahuan dari model besar masuk akal? Bayangkan kamu sudah mahir berjalan; belajar berlari atau berdansa jadi lebih mudah karena fondasinya sama.\n",
    "3. Kapan cukup melakukan freeze? Kapan perlu fine-tune beberapa layer terakhir? Refleksikan situasi ketika kamu harus meningkatkan kemampuan dari berjalan santai ke sprint karena tuntutan tugas berbeda.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e20cfc1",
   "metadata": {},
   "source": [
    "## C. Ringkasan Teori\n",
    "\n",
    "Transfer learning adalah pendekatan reuse model terlatih sebagai titik awal agar hemat komputasi, data, dan waktu; kamu tidak selalu harus memulai training dari nol. Intinya, representasi fitur yang sudah kaya dipakai ulang lalu disesuaikan pada tugas baru.\n",
    "\n",
    "**Manfaat & Kelebihan**\n",
    "- **Efisiensi training:** mengurangi epochs dan percobaan trial-and-error.\n",
    "- **Kebutuhan data lebih sedikit:** cocok untuk domain dengan data mahal seperti medis.\n",
    "- **Stabilitas performa:** membantu model konvergen pada solusi yang lebih baik.\n",
    "- **Mitigasi overfitting:** pengetahuan awal dari dataset besar bertindak sebagai regularizer.\n",
    "\n",
    "**Jenis-jenis Transfer Learning**\n",
    "1. *Inductive TL:* label tersedia di domain target; tugas sumber boleh berbeda (contoh: pretraining ImageNet lalu klasifikasi retinal fundus).\n",
    "2. *Transductive TL:* label target minim, domain sumber mirip; fokus pada adaptasi distribusi (contoh: domain adaptation).\n",
    "3. *Unsupervised TL:* reuse representasi tanpa label target, lalu gunakan metode lain di atas embedding.\n",
    "\n",
    "**Strategi Adaptasi Model**\n",
    "- **Feature Extraction (Freeze):** membekukan backbone, melatih classifier head baru. Analoginya: kamu sudah mahir berjalan, cukup belajar memegang benda sambil berjalan.\n",
    "- **Fine-Tuning Parsial:** membuka beberapa blok terakhir untuk menyesuaikan fitur tingkat tinggi—seperti belajar jogging ringan setelah lama berjalan agar tubuh menyesuaikan beban baru.\n",
    "- **Fine-Tuning Penuh:** melatih seluruh backbone; ibarat melatih ulang teknik berlari cepat dari nol karena kamu berpindah ke olahraga yang berbeda jauh.\n",
    "\n",
    "**Istilah Penting**\n",
    "- *Backbone:* model dasar penyedia fitur.\n",
    "- *Classifier Head:* lapisan akhir sesuai tugas target.\n",
    "- *Layer Freezing:* menonaktifkan grad agar bobot tetap.\n",
    "- *Domain Gap:* beda karakteristik antara data sumber dan target; makin besar gap, makin banyak adaptasi diperlukan.\n",
    "\n",
    "Catat analogi versi kamu sendiri untuk tiap strategi agar konsepnya melekat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869200f9",
   "metadata": {},
   "source": [
    "## D. Setup Lingkungan\n",
    "\n",
    "Bagian ini memastikan lingkungan eksekusi siap sebelum kamu menjalankan eksperimen.\n",
    "\n",
    "**Langkah Kamu**\n",
    "1. Jalankan kode di bawah untuk memuat dependensi dan utility.\n",
    "2. Perhatikan pesan versi Python, PyTorch, dan ketersediaan GPU.\n",
    "3. Pastikan folder `outputs/` dibuat otomatis; gunakan untuk menyimpan artefak.\n",
    "\n",
    "**Checklist Pribadi**\n",
    "- Sudah melakukan `pip install -r requirements.txt`.\n",
    "- Environment (conda/virtualenv) aktif denga versi paket sesuai kebutuhan.\n",
    "- Jika hanya punya CPU, berdoa saja agar bisa beli GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da24868a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/juni/Praktikum/deep-learning/transfer-learning-practicum\n",
      "Python version: 3.12.3\n",
      "PyTorch version: 2.8.0+cu128\n",
      "CUDA available: False\n",
      "Seed set to: 42\n",
      "Selected device: cpu\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import platform\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.transforms import functional as F_transforms\n",
    "import yaml\n",
    "\n",
    "# Fungsi utilitas agar hasil eksperimen deterministik untuk kebutuhan praktikum.\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    \"\"\"Set random seeds untuk numpy, random, dan torch agar hasil reproducible.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def get_device(preference: str = \"cuda_if_available\") -> torch.device:\n",
    "    \"\"\"Pilih device berdasarkan preferensi dan ketersediaan CUDA.\"\"\"\n",
    "    if preference == \"cuda_if_available\" and torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "# Deteksi root project (notebook berada di folder notebooks/).\n",
    "project_root = Path.cwd().resolve()\n",
    "if project_root.name == \"notebooks\":\n",
    "    project_root = project_root.parent\n",
    "\n",
    "paths_to_create = [\n",
    "    project_root / \"outputs\" / \"figures\",\n",
    "    project_root / \"outputs\" / \"reports\",\n",
    "    project_root / \"models\",\n",
    "]\n",
    "for path in paths_to_create:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Simpan cache weight torchvision ke folder models/ agar rapih (dan reusable jika tersedia).\n",
    "os.environ.setdefault(\"TORCH_HOME\", str(project_root / \"models\"))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python version: {platform.python_version()}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "seed_value = 42\n",
    "set_seed(seed_value)\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Seed set to: {seed_value}\")\n",
    "print(f\"Selected device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee0b76a",
   "metadata": {},
   "source": [
    "## E. Konfigurasi (Code)\n",
    "\n",
    "Konfigurasi dipisahkan melalui file YAML agar eksperimen mudah direplikasi dan dipersonalisasi.\n",
    "\n",
    "**Apa yang Harus Kamu Lakukan**\n",
    "- Baca konfigurasi yang ditampilkan sebagai tabel untuk memahami parameter default (jumlah kelas, ukuran input, strategi freeze).\n",
    "- Catat bagaimana `num_workers`, `batch_size`, dan `learning_rate` mempengaruhi waktu training.\n",
    "- Ubah satu parameter (misalnya `learning_rate`) dan dokumentasikan dampaknya sebagai bagian refleksi.\n",
    "\n",
    "Anggap konfigurasi ini seperti rencana latihan: kamu bisa menyesuaikan intensitas (learning rate) ketika merasa sudah siap “berlari” lebih cepat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bdb8bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>seed</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device</th>\n",
       "      <td>cuda_if_available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_workers</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_epochs_feature_extraction</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_epochs_fine_tuning</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer</th>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_feature_extraction</th>\n",
       "      <td>1e-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_fine_tuning</th>\n",
       "      <td>1e-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_decay</th>\n",
       "      <td>1e-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretrained_backbone</th>\n",
       "      <td>resnet18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freeze_until</th>\n",
       "      <td>layer4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_dir</th>\n",
       "      <td>outputs/reports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fig_dir</th>\n",
       "      <td>outputs/figures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>save_dir</th>\n",
       "      <td>models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_name</th>\n",
       "      <td>cifar10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_root</th>\n",
       "      <td>data/raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>download_dataset</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_subset_fraction</th>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_subset_fraction</th>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_train_samples</th>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_val_samples</th>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           value\n",
       "parameter                                       \n",
       "seed                                          42\n",
       "device                         cuda_if_available\n",
       "batch_size                                    16\n",
       "num_workers                                    2\n",
       "num_epochs_feature_extraction                  2\n",
       "num_epochs_fine_tuning                         2\n",
       "optimizer                                   adam\n",
       "lr_feature_extraction                       1e-3\n",
       "lr_fine_tuning                              1e-4\n",
       "weight_decay                                1e-4\n",
       "pretrained_backbone                     resnet18\n",
       "freeze_until                              layer4\n",
       "log_dir                          outputs/reports\n",
       "fig_dir                          outputs/figures\n",
       "save_dir                                  models\n",
       "dataset_name                             cifar10\n",
       "data_root                               data/raw\n",
       "download_dataset                            True\n",
       "train_subset_fraction                       0.05\n",
       "val_subset_fraction                          0.1\n",
       "max_train_samples                           1024\n",
       "max_val_samples                              512"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konfigurasi dimuat dari: /home/juni/Praktikum/deep-learning/transfer-learning-practicum/configs/training.yaml\n",
      "Seed aktif: 42\n",
      "Device aktif: cpu\n",
      "num_workers efektif: 2\n",
      "Data root: /home/juni/Praktikum/deep-learning/transfer-learning-practicum/data/raw\n"
     ]
    }
   ],
   "source": [
    "# Membaca konfigurasi template agar eksperimen mudah direplikasi.\n",
    "config_path = project_root / \"configs\" / \"training.yaml\"\n",
    "with config_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Menormalkan nilai num_workers agar aman dijalankan lintas OS / notebook.\n",
    "num_workers_cfg = int(config.get(\"num_workers\", 0))\n",
    "if os.name == \"nt\":\n",
    "    num_workers_cfg = 0  # Windows + notebook lebih stabil single-thread loader.\n",
    "if num_workers_cfg < 0:\n",
    "    num_workers_cfg = 0\n",
    "config[\"num_workers\"] = num_workers_cfg\n",
    "\n",
    "config_df = pd.DataFrame(list(config.items()), columns=[\"parameter\", \"value\"]).set_index(\"parameter\")\n",
    "display(config_df)\n",
    "\n",
    "seed_value = config.get(\"seed\", seed_value)\n",
    "set_seed(seed_value)\n",
    "device = get_device(config.get(\"device\", \"cuda_if_available\"))\n",
    "\n",
    "data_root_path = (project_root / config.get(\"data_root\", \"data/raw\")).resolve()\n",
    "data_root_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Konfigurasi dimuat dari: {config_path}\")\n",
    "print(f\"Seed aktif: {seed_value}\")\n",
    "print(f\"Device aktif: {device}\")\n",
    "print(f\"num_workers efektif: {config['num_workers']}\")\n",
    "print(f\"Data root: {data_root_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8921e8ed",
   "metadata": {},
   "source": [
    "## F. DataModule Real-World (Code)\n",
    "\n",
    "Pipeline data kini menggunakan dataset nyata untuk latihan. Secara default notebook memuat CIFAR-10 melalui `torchvision.datasets`,\n",
    "n kemudian membatasi sebagian sampel agar latihan cepat dijalankan di kelas/lab. Kamu dapat menggantinya dengan dataset\n",
    "berbasis `ImageFolder` (struktur `train/` dan `val/`) tanpa perlu mengubah logika training yang lain.\n",
    "\n",
    "**Langkah Mahasiswa**\n",
    "- Pastikan koneksi internet aktif saat pertama kali mengunduh CIFAR-10, atau siapkan salinan lokal di `data/raw`.\n",
    "- Ubah parameter `train_subset_fraction` dan `val_subset_fraction` pada `configs/training.yaml` jika ingin menggunakan seluruh dataset.\n",
    "- Jika memakai dataset sendiri, set `dataset_name: imagefolder` dan arahkan `data_root` ke direktori yang memuat subfolder `train/` dan `val/`.\n",
    "\n",
    "Bayangkan proses ini seperti berlatih dari lagu nyata setelah menyiapkan teknik dasar: kita tidak lagi memainkan nada acak,\n",
    "melainkan menyesuaikan keterampilan ke karya yang sesungguhnya.\n",
    "\n",
    "**Ringkasan cepat:** notebook otomatis membatasi sampel (parameter `train_subset_fraction`, `max_train_samples`). Lihat log setelah menjalankan sel ini untuk memastikan jumlah batch tidak berlebihan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7ec6631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CIFAR10 | kelas: 10\n",
      "Train subset: 1024 sampel (batch torch.Size([16, 3, 224, 224]))\n",
      "Val subset: 512 sampel (batch torch.Size([16, 3, 224, 224]))\n"
     ]
    }
   ],
   "source": [
    "# DataModule untuk dataset citra nyata (CIFAR-10 sebagai default, ImageFolder sebagai opsi lanjutan).\n",
    "class ImageClassificationDataModule:\n",
    "    \"\"\"Memuat dataset klasifikasi citra dan menyediakan DataLoader untuk training/validasi.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_name: str,\n",
    "        data_root: Path,\n",
    "        batch_size: int,\n",
    "        num_workers: int,\n",
    "        seed: int,\n",
    "        train_subset_fraction: float = 1.0,\n",
    "        val_subset_fraction: float = 1.0,\n",
    "        max_train_samples: int | None = None,\n",
    "        max_val_samples: int | None = None,\n",
    "        download: bool = True,\n",
    "    ) -> None:\n",
    "        self.dataset_name = dataset_name.lower()\n",
    "        self.data_root = data_root\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = max(0, int(num_workers))\n",
    "        if os.name == \"nt\":\n",
    "            self.num_workers = 0\n",
    "        self.seed = seed\n",
    "        self.train_subset_fraction = float(train_subset_fraction)\n",
    "        self.val_subset_fraction = float(val_subset_fraction)\n",
    "        self.max_train_samples = None if max_train_samples is None else int(max_train_samples)\n",
    "        self.max_val_samples = None if max_val_samples is None else int(max_val_samples)\n",
    "        self.download = bool(download)\n",
    "\n",
    "        self.train_transforms = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        self.eval_transforms = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        self.num_classes = None\n",
    "\n",
    "    def setup(self) -> None:\n",
    "        if self.dataset_name == \"cifar10\":\n",
    "            train_full = datasets.CIFAR10(\n",
    "                root=self.data_root,\n",
    "                train=True,\n",
    "                transform=self.train_transforms,\n",
    "                download=self.download,\n",
    "            )\n",
    "            val_full = datasets.CIFAR10(\n",
    "                root=self.data_root,\n",
    "                train=False,\n",
    "                transform=self.eval_transforms,\n",
    "                download=self.download,\n",
    "            )\n",
    "            self.num_classes = len(train_full.classes)\n",
    "        elif self.dataset_name == \"imagefolder\":\n",
    "            train_dir = self.data_root / \"train\"\n",
    "            val_dir = self.data_root / \"val\"\n",
    "            if not train_dir.exists() or not val_dir.exists():\n",
    "                raise FileNotFoundError(\n",
    "                    \"Direktori imagefolder tidak ditemukan. Pastikan memiliki subfolder 'train/' dan 'val/'.\"\n",
    "                )\n",
    "            train_full = datasets.ImageFolder(train_dir, transform=self.train_transforms)\n",
    "            val_full = datasets.ImageFolder(val_dir, transform=self.eval_transforms)\n",
    "            self.num_classes = len(train_full.classes)\n",
    "        else:\n",
    "            raise ValueError(\"dataset_name hanya mendukung 'cifar10' atau 'imagefolder' untuk saat ini.\")\n",
    "\n",
    "        self.train_dataset = self._maybe_subset(\n",
    "            train_full,\n",
    "            fraction=self.train_subset_fraction,\n",
    "            max_samples=self.max_train_samples,\n",
    "        )\n",
    "        self.val_dataset = self._maybe_subset(\n",
    "            val_full,\n",
    "            fraction=self.val_subset_fraction,\n",
    "            max_samples=self.max_val_samples,\n",
    "        )\n",
    "\n",
    "    def _maybe_subset(self, dataset, fraction: float, max_samples: int | None):\n",
    "        total_len = len(dataset)\n",
    "        target_len = total_len\n",
    "        fraction = float(max(0.0, min(fraction, 1.0)))\n",
    "        if fraction < 1.0:\n",
    "            target_len = max(1, int(total_len * fraction))\n",
    "        if max_samples is not None:\n",
    "            target_len = max(1, min(target_len, max_samples))\n",
    "        if target_len >= total_len:\n",
    "            return dataset\n",
    "        generator = torch.Generator().manual_seed(self.seed)\n",
    "        indices = torch.randperm(total_len, generator=generator)[:target_len].tolist()\n",
    "        return Subset(dataset, indices)\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=torch.cuda.is_available(),\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=torch.cuda.is_available(),\n",
    "        )\n",
    "\n",
    "\n",
    "dataset_name_cfg = config.get(\"dataset_name\", \"cifar10\")\n",
    "train_subset_fraction = config.get(\"train_subset_fraction\", 1.0)\n",
    "val_subset_fraction = config.get(\"val_subset_fraction\", 1.0)\n",
    "max_train_samples = config.get(\"max_train_samples\")\n",
    "max_val_samples = config.get(\"max_val_samples\")\n",
    "download_dataset = config.get(\"download_dataset\", True)\n",
    "\n",
    "datamodule = ImageClassificationDataModule(\n",
    "    dataset_name=dataset_name_cfg,\n",
    "    data_root=data_root_path,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    num_workers=config[\"num_workers\"],\n",
    "    seed=seed_value,\n",
    "    train_subset_fraction=train_subset_fraction,\n",
    "    val_subset_fraction=val_subset_fraction,\n",
    "    max_train_samples=max_train_samples,\n",
    "    max_val_samples=max_val_samples,\n",
    "    download=download_dataset,\n",
    ")\n",
    "\n",
    "datamodule.setup()\n",
    "NUM_CLASSES = datamodule.num_classes\n",
    "\n",
    "sample_train_batch = next(iter(datamodule.train_dataloader()))\n",
    "sample_val_batch = next(iter(datamodule.val_dataloader()))\n",
    "print(f\"Dataset: {dataset_name_cfg.upper()} | kelas: {NUM_CLASSES}\")\n",
    "print(\n",
    "    f\"Train subset: {len(datamodule.train_dataset)} sampel (batch {sample_train_batch[0].shape})\"\n",
    ")\n",
    "print(\n",
    "    f\"Val subset: {len(datamodule.val_dataset)} sampel (batch {sample_val_batch[0].shape})\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2525d1ea",
   "metadata": {},
   "source": [
    "## G. Bangun Model Pretrained (Code)\n",
    "\n",
    "Mengambil backbone pretrained (`resnet18`), memisahkan feature extractor vs classifier, serta menyiapkan fungsi freeze atau unfreeze untuk mode feature extraction dan fine-tuning.\n",
    "\n",
    "**Hal yang Perlu Diamati**\n",
    "- Perhatikan bagaimana fungsi `build_backbone` mengganti classifier head.\n",
    "- Pikirkan arti parameter `pretrained=True` dan sumber bobot (ImageNet).\n",
    "- Modifikasi `NUM_CLASSES` lalu amati perubahan ukuran layer akhir.\n",
    "\n",
    "Analoginya, backbone pretrained adalah otot dasar yang sudah terlatih berjalan. Kamu menambahkan “skill baru” (classifier head) agar bisa berlari mengikuti lomba tertentu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7045d271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone weight source: ResNet18_Weights.DEFAULT\n",
      "Trainable params (feature extraction): 5130\n",
      "Trainable params (fine-tuning policy 'layer4'): 8398858\n"
     ]
    }
   ],
   "source": [
    "# Utilitas pemodelan untuk memisahkan backbone dan classifier.\n",
    "def build_backbone(name: str = \"resnet18\", pretrained: bool = True, num_classes: int | None = None):\n",
    "    \"\"\"Membangun backbone torchvision dan memisahkan classifier head.\"\"\"\n",
    "    if name != \"resnet18\":\n",
    "        raise ValueError(\"Demo ini saat ini hanya mendukung resnet18 sebagai baseline ringan.\")\n",
    "\n",
    "    if num_classes is None:\n",
    "        if \"NUM_CLASSES\" not in globals():\n",
    "            raise ValueError(\"NUM_CLASSES belum terdefinisi. Jalankan sel DataModule terlebih dahulu.\")\n",
    "        num_classes = NUM_CLASSES\n",
    "\n",
    "    base_model = None\n",
    "    weights_info = \"random-init\"\n",
    "    if pretrained:\n",
    "        try:\n",
    "            if hasattr(models, \"ResNet18_Weights\"):\n",
    "                base_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "                weights_info = \"ResNet18_Weights.DEFAULT\"\n",
    "            else:\n",
    "                base_model = models.resnet18(pretrained=True)\n",
    "                weights_info = \"pretrained=True\"\n",
    "        except Exception as exc:\n",
    "            print(f\"Gagal memuat weight pretrained (offline?): {exc}\")\n",
    "            weights_info = \"random-init (fallback)\"\n",
    "\n",
    "    if base_model is None:\n",
    "        if hasattr(models, \"ResNet18_Weights\"):\n",
    "            base_model = models.resnet18(weights=None)\n",
    "        else:\n",
    "            base_model = models.resnet18(pretrained=False)\n",
    "\n",
    "    feature_extractor = nn.Sequential(*list(base_model.children())[:-1])\n",
    "    in_features = base_model.fc.in_features\n",
    "    classifier = nn.Linear(in_features, num_classes)\n",
    "    return feature_extractor, classifier, weights_info\n",
    "\n",
    "\n",
    "class TransferLearner(nn.Module):\n",
    "    \"\"\"Model wrapper yang memisahkan feature extractor dan classifier.\"\"\"\n",
    "    def __init__(self, feature_extractor: nn.Module, classifier: nn.Module) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.feature_extractor(x)\n",
    "        features = torch.flatten(features, 1)\n",
    "        return self.classifier(features)\n",
    "\n",
    "\n",
    "def set_feature_extractor_grad(feature_extractor: nn.Module, freeze_until: str = \"all\") -> None:\n",
    "    \"\"\"Atur parameter backbone yang dapat di-train sesuai kebijakan freeze.\"\"\"\n",
    "    freeze_until = freeze_until.lower()\n",
    "    if freeze_until not in {\"all\", \"layer4\", \"none\"}:\n",
    "        raise ValueError(\"freeze_until harus salah satu dari: all | layer4 | none\")\n",
    "\n",
    "    for param in feature_extractor.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    if freeze_until == \"layer4\":\n",
    "        for name, module in feature_extractor.named_children():\n",
    "            if name == \"7\":\n",
    "                for param in module.parameters():\n",
    "                    param.requires_grad = True\n",
    "    elif freeze_until == \"none\":\n",
    "        for param in feature_extractor.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "def count_trainable_parameters(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "feature_extractor, classifier, weights_info = build_backbone(\n",
    "    name=config.get(\"pretrained_backbone\", \"resnet18\"),\n",
    "    pretrained=True,\n",
    "    num_classes=NUM_CLASSES,\n",
    ")\n",
    "print(f\"Backbone weight source: {weights_info}\")\n",
    "model = TransferLearner(feature_extractor, classifier).to(device)\n",
    "\n",
    "# Mode feature extraction: seluruh backbone di-freeze.\n",
    "set_feature_extractor_grad(model.feature_extractor, freeze_until=\"all\")\n",
    "fe_params = count_trainable_parameters(model)\n",
    "print(f\"Trainable params (feature extraction): {fe_params}\")\n",
    "\n",
    "# Mode fine-tuning: buka sesuai konfigurasi freeze_until.\n",
    "set_feature_extractor_grad(model.feature_extractor, freeze_until=config.get(\"freeze_until\"))\n",
    "ft_params = count_trainable_parameters(model)\n",
    "print(f\"Trainable params (fine-tuning policy '{config.get('freeze_until', 'all')}'): {ft_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73368c8",
   "metadata": {},
   "source": [
    "## H. Loop Train Generic (Code)\n",
    "\n",
    "Loop training ini mendemokan dua tahap: feature extraction (melatih classifier saja) dan fine-tuning (opsional membuka sebagian backbone). Logging masih sederhana karena dataset dummy.\n",
    "\n",
    "**Panduan Praktik**\n",
    "- Jalankan sel training dan amati output loss/akurasi setiap epoch.\n",
    "- Tuliskan perbedaan dinamika antara tahap feature extraction dan fine-tuning.\n",
    "- Eksperimen: ubah jumlah epoch atau buka lebih banyak layer lalu bandingkan hasilnya.\n",
    "\n",
    "Pikirkan transisi freeze → fine-tune seperti beralih dari jalan santai ke lari interval: kamu perlu menyesuaikan kecepatan, napas (learning rate), dan durasi agar tubuh (model) tetap stabil.\n",
    "\n",
    "**Cara membaca output:** perhatikan baris `[feature_extraction]` dan `[fine_tuning]` yang muncul di terminal. Itu menunjukkan epoch, loss, dan akurasi sehingga kamu bisa menghentikan eksekusi bila sudah cukup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d0b49a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feature_extraction] Epoch 1/2 — train_loss=2.1256 val_loss=1.7530 train_acc=0.249 val_acc=0.389\n",
      "[feature_extraction] Epoch 2/2 — train_loss=1.4771 val_loss=1.3619 train_acc=0.527 val_acc=0.527\n",
      "[fine_tuning] Epoch 1/2 — train_loss=0.9324 val_loss=0.7697 train_acc=0.702 val_acc=0.732\n",
      "[fine_tuning] Epoch 2/2 — train_loss=0.4932 val_loss=0.6940 train_acc=0.842 val_acc=0.756\n",
      "Selesai training demo dengan 4 entry riwayat.\n"
     ]
    }
   ],
   "source": [
    "# Fungsi training sederhana agar pipeline dapat dijalankan end-to-end.\n",
    "def train_one_epoch(model: nn.Module, dataloader: DataLoader, criterion, optimizer, device: torch.device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / max(total, 1)\n",
    "    epoch_acc = correct / max(total, 1)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module, dataloader: DataLoader, criterion, device: torch.device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    epoch_loss = running_loss / max(total, 1)\n",
    "    epoch_acc = correct / max(total, 1)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def run_training_cycles(model: nn.Module, datamodule: ImageClassificationDataModule, config: dict, device: torch.device):\n",
    "    history = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_loader = datamodule.train_dataloader()\n",
    "    val_loader = datamodule.val_dataloader()\n",
    "\n",
    "    lr_fe = float(config[\"lr_feature_extraction\"])\n",
    "    lr_ft = float(config[\"lr_fine_tuning\"])\n",
    "    weight_decay = float(config[\"weight_decay\"])\n",
    "\n",
    "    # Tahap 1: Feature Extraction (freeze backbone).\n",
    "    feature_epochs = int(config[\"num_epochs_feature_extraction\"])\n",
    "    set_feature_extractor_grad(model.feature_extractor, freeze_until=\"all\")\n",
    "    optimizer_fe = optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=lr_fe,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "    for epoch in range(1, feature_epochs + 1):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer_fe, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        history.append({\n",
    "            \"stage\": \"feature_extraction\",\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": float(train_loss),\n",
    "            \"train_acc\": float(train_acc),\n",
    "            \"val_loss\": float(val_loss),\n",
    "            \"val_acc\": float(val_acc),\n",
    "        })\n",
    "        print(\n",
    "            f\"[feature_extraction] Epoch {epoch}/{feature_epochs} — \"\n",
    "            f\"train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n",
    "            f\"train_acc={train_acc:.3f} val_acc={val_acc:.3f}\"\n",
    "        )\n",
    "\n",
    "    # Tahap 2: Fine-tuning (opsional membuka layer backbone).\n",
    "    fine_tune_epochs = int(config.get(\"num_epochs_fine_tuning\", 0))\n",
    "    if fine_tune_epochs > 0:\n",
    "        set_feature_extractor_grad(model.feature_extractor, freeze_until=config.get(\"freeze_until\", \"all\"))\n",
    "        optimizer_ft = optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            lr=lr_ft,\n",
    "            weight_decay=weight_decay,\n",
    "        )\n",
    "        for epoch in range(1, fine_tune_epochs + 1):\n",
    "            train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer_ft, device)\n",
    "            val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "            history.append({\n",
    "                \"stage\": \"fine_tuning\",\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": float(train_loss),\n",
    "                \"train_acc\": float(train_acc),\n",
    "                \"val_loss\": float(val_loss),\n",
    "                \"val_acc\": float(val_acc),\n",
    "            })\n",
    "            print(\n",
    "                f\"[fine_tuning] Epoch {epoch}/{fine_tune_epochs} — \"\n",
    "                f\"train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n",
    "                f\"train_acc={train_acc:.3f} val_acc={val_acc:.3f}\"\n",
    "            )\n",
    "    else:\n",
    "        print(\"Tahap fine_tuning dilewati (num_epochs_fine_tuning=0).\")\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "history = run_training_cycles(model, datamodule, config, device)\n",
    "print(f\"Selesai training demo dengan {len(history)} entry riwayat.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca485dab",
   "metadata": {},
   "source": [
    "## I. Plot & Logging (Code)\n",
    "\n",
    "Visualisasi metrik dummy dan simpan artefak (plot serta ringkasan JSON) ke folder `outputs/` agar mudah diperiksa setelah praktikum.\n",
    "\n",
    "**Langkah Observasi**\n",
    "- Bandingkan kurva loss antar tahap; tuliskan observasi di jurnal belajar.\n",
    "- Screenshot tabel `history_df` atau catat angka penting (misal stagnasi akurasi) sebagai bahan diskusi.\n",
    "- Buka file JSON atau figur di `outputs/` lalu verifikasi penamaan file sesuai standar tim.\n",
    "\n",
    "Gunakan analogi latihan fisik: grafik loss adalah detak jantungmu. Saat mulai “berlari” (fine-tune), apakah detak meningkat (loss naik) sebelum turun stabil? Catat interpretasimu.\n",
    "\n",
    "**Sebelum lanjut:** pastikan file pada `outputs/figures` dan `outputs/reports` sudah terbuat. Jika belum, ulangi sel training lalu jalankan sel ini lagi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d817743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feature_extraction</td>\n",
       "      <td>1</td>\n",
       "      <td>2.125630</td>\n",
       "      <td>0.249023</td>\n",
       "      <td>1.753035</td>\n",
       "      <td>0.388672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feature_extraction</td>\n",
       "      <td>2</td>\n",
       "      <td>1.477140</td>\n",
       "      <td>0.527344</td>\n",
       "      <td>1.361905</td>\n",
       "      <td>0.527344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fine_tuning</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932377</td>\n",
       "      <td>0.702148</td>\n",
       "      <td>0.769742</td>\n",
       "      <td>0.732422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fine_tuning</td>\n",
       "      <td>2</td>\n",
       "      <td>0.493241</td>\n",
       "      <td>0.841797</td>\n",
       "      <td>0.694042</td>\n",
       "      <td>0.755859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                stage  epoch  train_loss  train_acc  val_loss   val_acc\n",
       "0  feature_extraction      1    2.125630   0.249023  1.753035  0.388672\n",
       "1  feature_extraction      2    1.477140   0.527344  1.361905  0.527344\n",
       "2         fine_tuning      1    0.932377   0.702148  0.769742  0.732422\n",
       "3         fine_tuning      2    0.493241   0.841797  0.694042  0.755859"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot tersimpan di: /home/juni/Praktikum/deep-learning/transfer-learning-practicum/outputs/figures/loss_accuracy_demo.png\n",
      "Ringkasan run tersimpan di: /home/juni/Praktikum/deep-learning/transfer-learning-practicum/outputs/reports/run_summary.json\n",
      "Model checkpoint dummy tersimpan di: /home/juni/Praktikum/deep-learning/transfer-learning-practicum/models/demo_model_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "# Menyusun history ke DataFrame untuk analisis cepat.\n",
    "history_df = pd.DataFrame(history)\n",
    "if not history_df.empty:\n",
    "    display(history_df)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    for stage in history_df[\"stage\"].unique():\n",
    "        subset = history_df[history_df[\"stage\"] == stage]\n",
    "        axes[0].plot(subset[\"epoch\"], subset[\"train_loss\"], marker=\"o\", label=f\"{stage} train\")\n",
    "        axes[0].plot(subset[\"epoch\"], subset[\"val_loss\"], marker=\"s\", label=f\"{stage} val\")\n",
    "        axes[1].plot(subset[\"epoch\"], subset[\"train_acc\"], marker=\"o\", label=f\"{stage} train\")\n",
    "        axes[1].plot(subset[\"epoch\"], subset[\"val_acc\"], marker=\"s\", label=f\"{stage} val\")\n",
    "    axes[0].set_title(\"Loss per Stage\")\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].legend()\n",
    "    axes[1].set_title(\"Accuracy per Stage\")\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].set_ylabel(\"Accuracy\")\n",
    "    axes[1].legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig_path = project_root / config[\"fig_dir\"] / \"loss_accuracy_demo.png\"\n",
    "    fig.savefig(fig_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"Plot tersimpan di: {fig_path}\")\n",
    "else:\n",
    "    print(\"History kosong: tidak ada data untuk divisualisasikan.\")\n",
    "\n",
    "summary = {\n",
    "    \"device\": str(device),\n",
    "    \"config\": config,\n",
    "    \"history\": history,\n",
    "}\n",
    "summary_path = project_root / config[\"log_dir\"] / \"run_summary.json\"\n",
    "with summary_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(f\"Ringkasan run tersimpan di: {summary_path}\")\n",
    "\n",
    "model_path = project_root / config[\"save_dir\"] / \"demo_model_state_dict.pt\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model checkpoint dummy tersimpan di: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a6b836",
   "metadata": {},
   "source": [
    "## J. Ringkasan & Diskusi\n",
    "\n",
    "| Mode | Kecepatan | Kebutuhan Data | Risiko Overfitting | Kapan Dipilih |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Feature Extraction (Freeze) | Cepat (hanya train head) | Rendah | Rendah | Dataset kecil, domain mirip |\n",
    "| Fine-Tuning Parsial | Sedang (beberapa layer dibuka) | Menengah | Menengah | Saat butuh adaptasi moderat, layer akhir di-unfreeze |\n",
    "| Fine-Tuning Penuh | Paling lama | Tinggi | Lebih tinggi | Domain sangat berbeda, data cukup |\n",
    "\n",
    "**Pertanyaan Refleksi**\n",
    "- Jika analogi berjalan → jogging → sprint kamu terapkan, kapan kamu merasa siap naik tingkat dan mengapa?\n",
    "- Bagaimana mempersiapkan data tambahan (mis. augmentasi) agar transisi “lari” lebih stabil?\n",
    "- Jika performa tidak meningkat setelah fine-tuning, langkah diagnostik apa yang akan kamu coba terlebih dahulu?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26fb0f2",
   "metadata": {},
   "source": [
    "## K. Checklist Pemahaman\n",
    "\n",
    "Gunakan daftar berikut untuk mengecek pemahamanmu sebelum lanjut ke materi berikutnya.\n",
    "\n",
    "- [ ] Kamu dapat menjelaskan definisi dan manfaat transfer learning dengan bahasamu sendiri.\n",
    "- [ ] Kamu bisa membedakan freeze vs fine-tune beserta implikasi jumlah parameter yang dilatih.\n",
    "- [ ] Kamu tahu cara mengubah konfigurasi `freeze_until` serta menjelaskan dampaknya.\n",
    "- [ ] Kamu menemukan lokasi file output (`outputs/figures` dan `outputs/reports`) dan memahami isinya.\n",
    "- [ ] Kamu mampu menyebutkan minimal satu ide penerapan transfer learning pada bidang studi masing-masing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0217280",
   "metadata": {},
   "source": [
    "## L. Referensi\n",
    "\n",
    "- Slide: **Deep Learning 06 — Transfer Learning (Tatap Muka)** — ringkasan definisi, manfaat, jenis-jenis, serta strategi fine-tuning vs freeze yang digunakan dalam praktikum ini.\n",
    "- Buku: *Deep Learning* (Goodfellow et al.) Bab 15 mengenai representasi dan transfer.\n",
    "- Artikel: Pan dan Yang (2010) *A Survey on Transfer Learning* untuk memberikan landasan teori lebih formal.\n",
    "- Dokumentasi PyTorch Transfer Learning Tutorial — contoh resmi yang dapat dijadikan bacaan tambahan mahasiswa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f289c45f",
   "metadata": {},
   "source": [
    "## M. Panduan Langkah Transfer Learning\n",
    "\n",
    "Gunakan tahapan berikut sebagai rambu sederhana saat menerapkan transfer learning dari ImageNet ke Pascal VOC2007. Fokuslah pada konsep; kita menjaga beban komputasi tetap ringan.\n",
    "\n",
    "1. **Pilih backbone pretrained ImageNet.** Contoh: `torchvision.models.resnet18(weights=\"IMAGENET1K_V1\")`. Model ini sudah memahami bentuk umum seperti tepi, tekstur, dan pola objek.\n",
    "2. **Siapkan dataset target ringan.** VOC2007 dapat dimuat dengan subset kecil atau hanya beberapa kelas. Gunakan transformasi yang menyamakan ukuran dan normalisasi ke standar ImageNet.\n",
    "3. **Ganti classifier head.** Sesuaikan jumlah output dengan label VOC2007 (misal 20 kelas). Pada tahap ini kamu ibarat pemain biola yang mengganti skor musik menjadi pseudocode sementara ritme tetap sama.\n",
    "4. **Beku-kan layer awal.** Mulailah dengan mode feature extraction: matikan grad pada sebagian besar backbone sehingga hanya head yang belajar. Ini seperti berjalan santai sambil memegang biola, memindahkan rasa ritme ke latihan mengetik.\n",
    "5. **Latih dengan epoch singkat.** Gunakan batch kecil dan 3–5 epoch terlebih dahulu. Observasi loss dan akurasi; catat apa yang berubah.\n",
    "6. **Buka beberapa layer akhir bila diperlukan.** Jika performa stagnan, buka blok terakhir dan turunkan learning rate. Kini kamu beralih dari berjalan ke jogging, memadukan intuisi musikal dengan logika algoritmik.\n",
    "7. **Evaluasi dan catat insight.** Fokus pada apa yang kamu pelajari mengenai representasi fitur, bukan sekadar angka. Tanyakan: bagian mana yang paling banyak mentransfer pengetahuan?\n",
    "\n",
    "Iterasikan langkah-langkah ini secara bertahap; setiap siklus bagaikan mencoba genre musik baru sambil tetap membawa dasar teknik yang sama.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dcdf87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogi Transfer Learning:\n",
      "- Dari main biola ke ngoding: teknik mengenali pola irama dialihkan jadi logika if-else dan loop.\n",
      "- Dari berjalan santai ke sprint: mulai dengan freeze yang aman, lanjutkan fine-tune saat siap berlari.\n",
      "- Dari belajar bahasa serumpun ke bahasa baru: gunakan kosakata lama sebagai batu loncatan.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat <<'EOF'\n",
    "Analogi Transfer Learning:\n",
    "- Dari main biola ke ngoding: teknik mengenali pola irama dialihkan jadi logika if-else dan loop.\n",
    "- Dari berjalan santai ke sprint: mulai dengan freeze yang aman, lanjutkan fine-tune saat siap berlari.\n",
    "- Dari belajar bahasa serumpun ke bahasa baru: gunakan kosakata lama sebagai batu loncatan.\n",
    "EOF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ccafc",
   "metadata": {},
   "source": [
    "## N. Glosarium & Istilah Kunci\n",
    "\n",
    "- **Transfer Learning:** Teknik memanfaatkan model terlatih pada tugas berbeda sebagai titik awal tugas baru.\n",
    "- **Backbone:** Bagian utama jaringan (biasanya konvolusional) yang mengekstraksi fitur dari input.\n",
    "- **Classifier Head:** Lapisan akhir yang mengubah fitur menjadi prediksi kelas.\n",
    "- **Fine-Tuning:** Proses melatih ulang (sebagian) bobot pretrained agar menyesuaikan domain target.\n",
    "- **Freeze:** Menonaktifkan update grad pada layer tertentu.\n",
    "- **Feature Extraction:** Strategi menggunakan backbone beku untuk mengambil fitur lalu melatih classifier baru.\n",
    "- **Domain Gap:** Perbedaan karakteristik antara data sumber dan target; makin lebar gap, makin banyak adaptasi diperlukan.\n",
    "- **Early Stopping:** Teknik menghentikan training saat validasi tidak membaik untuk mencegah overfitting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
