{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94aeecc1",
   "metadata": {},
   "source": [
    "# Praktikum Deep Learning — Transfer Learning (Pengantar & Demo Konsep)\n",
    "\n",
    "_Notebook ini memandu kamu memahami konsep inti transfer learning sebelum terjun ke studi kasus medis. Gunakan sebagai pijakan awal: jalankan sel satu per satu, catat pengamatan, dan refleksikan apa yang terjadi._\n",
    "\n",
    "> Tips: aktifkan menu **View → Table of Contents** di JupyterLab supaya navigasi antar bagian lebih mudah.\n",
    "\n",
    "---\n",
    "\n",
    "**Profil Modul**\n",
    "- **Untuk siapa?** Mahasiswa yang sudah nyaman dengan CNN dasar dan Python.\n",
    "- **Durasi saran:** 2 x 50 menit (teori interaktif 40 menit, demo terarah 35 menit, refleksi 25 menit).\n",
    "- **Peran Notebook:** panduan belajar mandiri sekaligus skrip demonstrasi yang dapat kamu ulangi setelah sesi.\n",
    "\n",
    "**Mengapa Modul Ini Penting**\n",
    "- Kamu akan melihat langsung bagaimana reuse model pretrained menghemat waktu eksperimen.\n",
    "- Transfer learning membuatmu melangkah lebih jauh dengan data terbatas—ibarat sudah bisa berjalan, lalu belajar berlari tanpa harus tumbuh dari bayi lagi.\n",
    "- Bayangkan pemain biola yang beralih ke pemrograman: ia tidak mengulang belajar ritme dari nol, melainkan memindahkan sensitivitas tempo ke logika kode. Transfer learning bekerja dengan cara serupa, membawa keterampilan lama ke domain baru.\n",
    "\n",
    "**Apa yang Akan Kamu Lakukan**\n",
    "1. Menyegarkan kembali motivasi transfer learning dan menautkannya dengan pengalaman belajarmu.\n",
    "2. Menjalankan eksperimen terstruktur: konfigurasi, dataset dummy, dan modifikasi backbone.\n",
    "3. Menganalisis metrik dan mengaitkannya dengan strategi fine-tuning.\n",
    "4. Menyusun ide perluasan ringan untuk eksplorasi pribadi.\n",
    "\n",
    "**Prasyarat Teknis**\n",
    "- Memahami supervised learning, metrik akurasi, dan konsep overfitting.\n",
    "- Familiar dengan komponen PyTorch dasar (`DataLoader`, `nn.Module`, training loop).\n",
    "- Sudah memasang dependensi pada `requirements.txt`.\n",
    "\n",
    "**Hasil Belajar yang Diharapkan**\n",
    "- Catatan refleksi kapan memilih freeze vs fine-tuning.\n",
    "- Screenshot atau langkah analisis plot loss-akurasi di setiap tahap.\n",
    "- Draft ide adaptasi model untuk dataset pilihanmu sendiri.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e2e197",
   "metadata": {},
   "source": [
    "## A. Judul & Tujuan Pembelajaran\n",
    "\n",
    "Gunakan bagian ini untuk menyelaraskan harapan. Bacalah tujuan berikut, lalu tuliskan (misalnya di jurnal atau catatan digital) dua pertanyaan yang ingin kamu jawab setelah praktikum selesai.\n",
    "\n",
    "**Learning Objectives**\n",
    "- Memahami konsep dan motivasi Transfer Learning (hemat data, waktu, serta sumber daya komputasi) dan posisinya dalam pipeline deep learning modern.\n",
    "- Menjelaskan kelebihan utama pendekatan ini: efisiensi training, kebutuhan data lebih sedikit, performa stabil, dan mitigasi overfitting.\n",
    "- Mengidentifikasi variasi Transfer Learning (Inductive, Transductive, Unsupervised) serta kapan masing-masing cocok dipakai.\n",
    "- Membedakan mode feature extraction (freeze) vs fine-tuning penuh atau parsial, termasuk pengaruhnya pada jumlah parameter yang di-update.\n",
    "- Mengaplikasikan konfigurasi PyTorch untuk memuat backbone pretrained dan menyesuaikan classifier head.\n",
    "\n",
    "**Setelah Selesai Kamu Seharusnya Bisa**\n",
    "- Menyebutkan minimal dua alasan transfer learning relevan untuk dataset medis.\n",
    "- Menganalisis kapan harus membuka layer tambahan ketika domain target jauh dari domain sumber.\n",
    "- Memodifikasi hyperparameter dasar (learning rate, `freeze_until`) dan menuliskan implikasinya.\n",
    "\n",
    "**Pemanasan Cepat**\n",
    "- Bayangkan proses belajar berjalan: kamu tidak mengulang dari merangkak setiap kali belajar olahraga baru. Transfer learning bekerja dengan prinsip serupa. Catat analogi versimu sendiri di catatan praktikum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef3d316",
   "metadata": {},
   "source": [
    "## B. Recall & Icebreaker\n",
    "\n",
    "Luangkan 10 menit untuk kembali ke pengalamanmu sendiri. Jika belajar berkelompok, diskusikan jawaban; jika mandiri, tuliskan poin-poin penting.\n",
    "\n",
    "1. Apa tantangan melatih CNN dari nol ketika dataset kecil? Hubungkan dengan pengalamanmu memulai dari hal yang benar-benar baru tanpa referensi (ibarat belajar berjalan tanpa contoh).\n",
    "2. Mengapa reuse pengetahuan dari model besar masuk akal? Bayangkan kamu sudah mahir berjalan; belajar berlari atau berdansa jadi lebih mudah karena fondasinya sama.\n",
    "3. Kapan cukup melakukan freeze? Kapan perlu fine-tune beberapa layer terakhir? Refleksikan situasi ketika kamu harus meningkatkan kemampuan dari berjalan santai ke sprint karena tuntutan tugas berbeda.\n",
    "\n",
    "Tulislah jawaban di jurnal praktikum dan bandingkan dengan kawanmu setelah sesi untuk memperkaya perspektif.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e20cfc1",
   "metadata": {},
   "source": [
    "## C. Ringkasan Teori\n",
    "\n",
    "Transfer learning adalah pendekatan reuse model terlatih sebagai titik awal agar hemat komputasi, data, dan waktu; kamu tidak selalu harus memulai training dari nol. Intinya, representasi fitur yang sudah kaya dipakai ulang lalu disesuaikan pada tugas baru.\n",
    "\n",
    "**Manfaat & Kelebihan**\n",
    "- **Efisiensi training:** mengurangi epochs dan percobaan trial-and-error.\n",
    "- **Kebutuhan data lebih sedikit:** cocok untuk domain dengan data mahal seperti medis.\n",
    "- **Stabilitas performa:** membantu model konvergen pada solusi yang lebih baik.\n",
    "- **Mitigasi overfitting:** pengetahuan awal dari dataset besar bertindak sebagai regularizer.\n",
    "\n",
    "**Jenis-jenis Transfer Learning**\n",
    "1. *Inductive TL:* label tersedia di domain target; tugas sumber boleh berbeda (contoh: pretraining ImageNet lalu klasifikasi retinal fundus).\n",
    "2. *Transductive TL:* label target minim, domain sumber mirip; fokus pada adaptasi distribusi (contoh: domain adaptation).\n",
    "3. *Unsupervised TL:* reuse representasi tanpa label target, lalu gunakan metode lain di atas embedding.\n",
    "\n",
    "**Strategi Adaptasi Model**\n",
    "- **Feature Extraction (Freeze):** membekukan backbone, melatih classifier head baru. Analoginya: kamu sudah mahir berjalan, cukup belajar memegang benda sambil berjalan.\n",
    "- **Fine-Tuning Parsial:** membuka beberapa blok terakhir untuk menyesuaikan fitur tingkat tinggi—seperti belajar jogging ringan setelah lama berjalan agar tubuh menyesuaikan beban baru.\n",
    "- **Fine-Tuning Penuh:** melatih seluruh backbone; ibarat melatih ulang teknik berlari cepat dari nol karena kamu berpindah ke olahraga yang berbeda jauh.\n",
    "\n",
    "**Istilah Penting**\n",
    "- *Backbone:* model dasar penyedia fitur.\n",
    "- *Classifier Head:* lapisan akhir sesuai tugas target.\n",
    "- *Layer Freezing:* menonaktifkan grad agar bobot tetap.\n",
    "- *Domain Gap:* beda karakteristik antara data sumber dan target; makin besar gap, makin banyak adaptasi diperlukan.\n",
    "\n",
    "Catat analogi versi kamu sendiri untuk tiap strategi agar konsepnya melekat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869200f9",
   "metadata": {},
   "source": [
    "## D. Setup Lingkungan\n",
    "\n",
    "Bagian ini memastikan lingkungan eksekusi siap sebelum kamu menjalankan eksperimen.\n",
    "\n",
    "**Langkah Kamu**\n",
    "1. Jalankan kode di bawah untuk memuat dependensi dan utility.\n",
    "2. Perhatikan pesan versi Python, PyTorch, dan ketersediaan GPU.\n",
    "3. Pastikan folder `outputs/` dibuat otomatis; gunakan untuk menyimpan artefak.\n",
    "\n",
    "**Checklist Pribadi**\n",
    "- Sudah melakukan `pip install -r requirements.txt`.\n",
    "- Environment (conda/virtualenv) aktif denga versi paket sesuai kebutuhan.\n",
    "- Jika hanya punya CPU, perkirakan waktu eksekusi dan catat perbedaannya dibanding GPU (ini analogi berjalan pelan sebelum mampu berlari dengan dukungan GPU).\n",
    "\n",
    "Jika muncul error import, tangkap log dan tuliskan langkah debugging yang kamu coba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da24868a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/juni/Praktikum/deep-learning/transfer-learning-practicum\n",
      "Python version: 3.12.3\n",
      "PyTorch version: 2.8.0+cu128\n",
      "CUDA available: False\n",
      "Seed set to: 42\n",
      "Selected device: cpu\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import platform\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms import functional as F_transforms\n",
    "import yaml\n",
    "\n",
    "# Fungsi utilitas agar hasil eksperimen deterministik untuk kebutuhan praktikum.\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    \"\"\"Set random seeds untuk numpy, random, dan torch agar hasil reproducible.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def get_device(preference: str = \"cuda_if_available\") -> torch.device:\n",
    "    \"\"\"Pilih device berdasarkan preferensi dan ketersediaan CUDA.\"\"\"\n",
    "    if preference == \"cuda_if_available\" and torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "# Deteksi root project (notebook berada di folder notebooks/).\n",
    "project_root = Path.cwd().resolve()\n",
    "if project_root.name == \"notebooks\":\n",
    "    project_root = project_root.parent\n",
    "\n",
    "paths_to_create = [\n",
    "    project_root / \"outputs\" / \"figures\",\n",
    "    project_root / \"outputs\" / \"reports\",\n",
    "    project_root / \"models\",\n",
    "]\n",
    "for path in paths_to_create:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Simpan cache weight torchvision ke folder models/ agar rapih (dan reusable jika tersedia).\n",
    "os.environ.setdefault(\"TORCH_HOME\", str(project_root / \"models\"))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python version: {platform.python_version()}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "seed_value = 42\n",
    "set_seed(seed_value)\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Seed set to: {seed_value}\")\n",
    "print(f\"Selected device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee0b76a",
   "metadata": {},
   "source": [
    "## E. Konfigurasi (Code)\n",
    "\n",
    "Konfigurasi dipisahkan melalui file YAML agar eksperimen mudah direplikasi dan dipersonalisasi.\n",
    "\n",
    "**Apa yang Harus Kamu Lakukan**\n",
    "- Baca konfigurasi yang ditampilkan sebagai tabel untuk memahami parameter default (jumlah kelas, ukuran input, strategi freeze).\n",
    "- Catat bagaimana `num_workers`, `batch_size`, dan `learning_rate` mempengaruhi waktu training.\n",
    "- Ubah satu parameter (misalnya `learning_rate`) dan dokumentasikan dampaknya sebagai bagian refleksi.\n",
    "\n",
    "Anggap konfigurasi ini seperti rencana latihan: kamu bisa menyesuaikan intensitas (learning rate) ketika merasa sudah siap “berlari” lebih cepat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bdb8bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>seed</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device</th>\n",
       "      <td>cuda_if_available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_workers</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_epochs_feature_extraction</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_epochs_fine_tuning</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer</th>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_feature_extraction</th>\n",
       "      <td>1e-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_fine_tuning</th>\n",
       "      <td>1e-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_decay</th>\n",
       "      <td>1e-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretrained_backbone</th>\n",
       "      <td>resnet18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freeze_until</th>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_dir</th>\n",
       "      <td>outputs/reports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fig_dir</th>\n",
       "      <td>outputs/figures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>save_dir</th>\n",
       "      <td>models</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           value\n",
       "parameter                                       \n",
       "seed                                          42\n",
       "device                         cuda_if_available\n",
       "batch_size                                    16\n",
       "num_workers                                    2\n",
       "num_epochs_feature_extraction                  1\n",
       "num_epochs_fine_tuning                         1\n",
       "optimizer                                   adam\n",
       "lr_feature_extraction                       1e-3\n",
       "lr_fine_tuning                              1e-4\n",
       "weight_decay                                1e-4\n",
       "pretrained_backbone                     resnet18\n",
       "freeze_until                                 all\n",
       "log_dir                          outputs/reports\n",
       "fig_dir                          outputs/figures\n",
       "save_dir                                  models"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konfigurasi dimuat dari: /home/juni/Praktikum/deep-learning/transfer-learning-practicum/configs/training.yaml\n",
      "Seed aktif: 42\n",
      "Device aktif: cpu\n",
      "num_workers efektif: 2\n"
     ]
    }
   ],
   "source": [
    "# Membaca konfigurasi template agar eksperimen mudah direplikasi.\n",
    "config_path = project_root / \"configs\" / \"training.yaml\"\n",
    "with config_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Menormalkan nilai num_workers agar aman dijalankan lintas OS / notebook.\n",
    "num_workers_cfg = int(config.get(\"num_workers\", 0))\n",
    "if os.name == \"nt\":\n",
    "    num_workers_cfg = 0  # Windows + notebook lebih stabil single-thread loader.\n",
    "if num_workers_cfg < 0:\n",
    "    num_workers_cfg = 0\n",
    "config[\"num_workers\"] = num_workers_cfg\n",
    "\n",
    "config_df = pd.DataFrame(list(config.items()), columns=[\"parameter\", \"value\"]).set_index(\"parameter\")\n",
    "display(config_df)\n",
    "\n",
    "seed_value = config.get(\"seed\", seed_value)\n",
    "set_seed(seed_value)\n",
    "device = get_device(config.get(\"device\", \"cuda_if_available\"))\n",
    "print(f\"Konfigurasi dimuat dari: {config_path}\")\n",
    "print(f\"Seed aktif: {seed_value}\")\n",
    "print(f\"Device aktif: {device}\")\n",
    "print(f\"num_workers efektif: {config['num_workers']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8921e8ed",
   "metadata": {},
   "source": [
    "## F. Template DataModule (Code)\n",
    "\n",
    "Template DataModule sederhana berbasis dummy tensor untuk mendemokan alur. **TODO:** ganti dengan `torchvision.datasets.ImageFolder` atau dataset medis pada sesi studi kasus berikutnya. Transformasi menggunakan standar ImageNet agar konsisten dengan backbone pretrained.\n",
    "\n",
    "**Langkah Eksplorasi**\n",
    "- Jalankan kode dan perhatikan struktur kelas `DummyRandomDataset`.\n",
    "- Tandai bagian yang harus diganti saat memakai dataset asli (lokasi file, label, transformasi augmentasi).\n",
    "- Diskusikan atau tuliskan bagaimana menyeimbangkan augmentasi dengan keterbatasan data medis.\n",
    "\n",
    "Bayangkan dataset dummy ini seperti treadmill latihan: kamu belajar gerakan dasar sebelum turun ke lintasan asli.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7ec6631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contoh batch train: images torch.Size([16, 3, 224, 224]), labels torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# Dataset dummy agar loop training dapat dijalankan tanpa dataset eksternal.\n",
    "class DummyRandomDataset(Dataset):\n",
    "    \"\"\"Membuat sampel RGB acak dan label dummy untuk simulasi pipeline.\"\"\"\n",
    "    def __init__(self, num_samples: int, num_classes: int, transform=None, seed: int = 42) -> None:\n",
    "        self.num_samples = num_samples\n",
    "        self.num_classes = num_classes\n",
    "        self.transform = transform\n",
    "        gen = torch.Generator().manual_seed(seed)\n",
    "        self.images = torch.rand(num_samples, 3, 256, 256, generator=gen)\n",
    "        self.labels = torch.randint(0, num_classes, (num_samples,), generator=gen)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        pil_image = F_transforms.to_pil_image(image)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(pil_image)\n",
    "        else:\n",
    "            image = transforms.ToTensor()(pil_image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "class SimpleImageDataModule:\n",
    "    \"\"\"Kerangka DataModule minimal untuk praktikum transfer learning.\"\"\"\n",
    "    def __init__(self, batch_size: int, num_workers: int, num_classes: int = 2, seed: int = 42) -> None:\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = max(0, int(num_workers))\n",
    "        if os.name == \"nt\":\n",
    "            self.num_workers = 0  # Hindari multiprocessing issue pada Windows notebooks.\n",
    "        self.num_classes = num_classes\n",
    "        self.seed = seed\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        self.train_transforms = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        self.val_transforms = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "    def setup(self) -> None:\n",
    "        \"\"\"Membuat dataset dummy untuk train/val agar loop model dapat dieksekusi.\"\"\"\n",
    "        self.train_dataset = DummyRandomDataset(\n",
    "            num_samples=32,\n",
    "            num_classes=self.num_classes,\n",
    "            transform=self.train_transforms,\n",
    "            seed=self.seed,\n",
    "        )\n",
    "        self.val_dataset = DummyRandomDataset(\n",
    "            num_samples=16,\n",
    "            num_classes=self.num_classes,\n",
    "            transform=self.val_transforms,\n",
    "            seed=self.seed + 1,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "\n",
    "\n",
    "NUM_CLASSES = 2  # Ubah saat dataset sebenarnya tersedia.\n",
    "datamodule = SimpleImageDataModule(\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    num_workers=config[\"num_workers\"],\n",
    "    num_classes=NUM_CLASSES,\n",
    "    seed=seed_value,\n",
    ")\n",
    "datamodule.setup()\n",
    "train_batch = next(iter(datamodule.train_dataloader()))\n",
    "print(f\"Contoh batch train: images {train_batch[0].shape}, labels {train_batch[1].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2525d1ea",
   "metadata": {},
   "source": [
    "## G. Bangun Model Pretrained (Code)\n",
    "\n",
    "Mengambil backbone pretrained (`resnet18`), memisahkan feature extractor vs classifier, serta menyiapkan fungsi freeze atau unfreeze untuk mode feature extraction dan fine-tuning.\n",
    "\n",
    "**Hal yang Perlu Diamati**\n",
    "- Perhatikan bagaimana fungsi `build_backbone` mengganti classifier head.\n",
    "- Pikirkan arti parameter `pretrained=True` dan sumber bobot (ImageNet).\n",
    "- Modifikasi `NUM_CLASSES` lalu amati perubahan ukuran layer akhir.\n",
    "\n",
    "Analoginya, backbone pretrained adalah otot dasar yang sudah terlatih berjalan. Kamu menambahkan “skill baru” (classifier head) agar bisa berlari mengikuti lomba tertentu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7045d271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone weight source: ResNet18_Weights.DEFAULT\n",
      "Trainable params (feature extraction): 1026\n",
      "Trainable params (fine-tuning policy 'all'): 1026\n"
     ]
    }
   ],
   "source": [
    "# Utilitas pemodelan untuk memisahkan backbone dan classifier.\n",
    "def build_backbone(name: str = \"resnet18\", pretrained: bool = True, num_classes: int = NUM_CLASSES):\n",
    "    \"\"\"Membangun backbone torchvision dan memisahkan classifier head.\"\"\"\n",
    "    if name != \"resnet18\":\n",
    "        raise ValueError(\"Demo ini saat ini hanya mendukung resnet18 sebagai baseline ringan.\")\n",
    "\n",
    "    base_model = None\n",
    "    weights_info = \"random-init\"\n",
    "    if pretrained:\n",
    "        try:\n",
    "            if hasattr(models, \"ResNet18_Weights\"):\n",
    "                base_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "                weights_info = \"ResNet18_Weights.DEFAULT\"\n",
    "            else:\n",
    "                base_model = models.resnet18(pretrained=True)\n",
    "                weights_info = \"pretrained=True\"\n",
    "        except Exception as exc:\n",
    "            print(f\"Gagal memuat weight pretrained (offline?): {exc}\")\n",
    "            weights_info = \"random-init (fallback)\"\n",
    "\n",
    "    if base_model is None:\n",
    "        if hasattr(models, \"ResNet18_Weights\"):\n",
    "            base_model = models.resnet18(weights=None)\n",
    "        else:\n",
    "            base_model = models.resnet18(pretrained=False)\n",
    "\n",
    "    feature_extractor = nn.Sequential(*list(base_model.children())[:-1])\n",
    "    in_features = base_model.fc.in_features\n",
    "    classifier = nn.Linear(in_features, num_classes)\n",
    "    return feature_extractor, classifier, weights_info\n",
    "\n",
    "\n",
    "class TransferLearner(nn.Module):\n",
    "    \"\"\"Model wrapper yang memisahkan feature extractor dan classifier.\"\"\"\n",
    "    def __init__(self, feature_extractor: nn.Module, classifier: nn.Module) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.feature_extractor(x)\n",
    "        features = torch.flatten(features, 1)\n",
    "        return self.classifier(features)\n",
    "\n",
    "\n",
    "def set_feature_extractor_grad(feature_extractor: nn.Module, freeze_until: str = \"all\") -> None:\n",
    "    \"\"\"Atur parameter backbone yang dapat di-train sesuai kebijakan freeze.\"\"\"\n",
    "    freeze_until = freeze_until.lower()\n",
    "    if freeze_until not in {\"all\", \"layer4\", \"none\"}:\n",
    "        raise ValueError(\"freeze_until harus salah satu dari: all | layer4 | none\")\n",
    "\n",
    "    for param in feature_extractor.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    if freeze_until == \"layer4\":\n",
    "        # Layer ke-7 pada sequential merupakan block layer4 pada ResNet18.\n",
    "        for name, module in feature_extractor.named_children():\n",
    "            if name == \"7\":\n",
    "                for param in module.parameters():\n",
    "                    param.requires_grad = True\n",
    "    elif freeze_until == \"none\":\n",
    "        for param in feature_extractor.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "def count_trainable_parameters(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "feature_extractor, classifier, weights_info = build_backbone(\n",
    "    name=config.get(\"pretrained_backbone\", \"resnet18\"),\n",
    "    pretrained=True,\n",
    "    num_classes=NUM_CLASSES,\n",
    ")\n",
    "print(f\"Backbone weight source: {weights_info}\")\n",
    "model = TransferLearner(feature_extractor, classifier).to(device)\n",
    "\n",
    "# Mode feature extraction: seluruh backbone di-freeze.\n",
    "set_feature_extractor_grad(model.feature_extractor, freeze_until=\"all\")\n",
    "fe_params = count_trainable_parameters(model)\n",
    "print(f\"Trainable params (feature extraction): {fe_params}\")\n",
    "\n",
    "# Mode fine-tuning: buka sesuai konfigurasi freeze_until.\n",
    "set_feature_extractor_grad(model.feature_extractor, freeze_until=config.get(\"freeze_until\", \"all\"))\n",
    "ft_params = count_trainable_parameters(model)\n",
    "print(f\"Trainable params (fine-tuning policy '{config.get('freeze_until', 'all')}'): {ft_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73368c8",
   "metadata": {},
   "source": [
    "## H. Loop Train Generic (Code)\n",
    "\n",
    "Loop training minimalis ini mendemokan dua tahap: feature extraction (melatih classifier saja) dan fine-tuning (opsional membuka sebagian backbone). Logging masih sederhana karena dataset dummy.\n",
    "\n",
    "**Panduan Praktik**\n",
    "- Jalankan sel training dan amati output loss/akurasi setiap epoch.\n",
    "- Tuliskan perbedaan dinamika antara tahap feature extraction dan fine-tuning.\n",
    "- Eksperimen: ubah jumlah epoch atau buka lebih banyak layer lalu bandingkan hasilnya.\n",
    "\n",
    "Pikirkan transisi freeze → fine-tune seperti beralih dari jalan santai ke lari interval: kamu perlu menyesuaikan kecepatan, napas (learning rate), dan durasi agar tubuh (model) tetap stabil.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d0b49a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selesai training demo dengan 2 entry riwayat.\n"
     ]
    }
   ],
   "source": [
    "# Fungsi training sederhana agar pipeline dapat dijalankan end-to-end.\n",
    "def train_one_epoch(model: nn.Module, dataloader: DataLoader, criterion, optimizer, device: torch.device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / max(total, 1)\n",
    "    epoch_acc = correct / max(total, 1)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module, dataloader: DataLoader, criterion, device: torch.device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    epoch_loss = running_loss / max(total, 1)\n",
    "    epoch_acc = correct / max(total, 1)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def run_training_cycles(model: nn.Module, datamodule: SimpleImageDataModule, config: dict, device: torch.device):\n",
    "    history = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_loader = datamodule.train_dataloader()\n",
    "    val_loader = datamodule.val_dataloader()\n",
    "\n",
    "    # Pastikan nilai learning rate adalah float\n",
    "    lr_fe = float(config[\"lr_feature_extraction\"])\n",
    "    lr_ft = float(config[\"lr_fine_tuning\"])\n",
    "    weight_decay = float(config[\"weight_decay\"])\n",
    "\n",
    "    # Tahap 1: Feature Extraction (freeze backbone).\n",
    "    set_feature_extractor_grad(model.feature_extractor, freeze_until=\"all\")\n",
    "    optimizer_fe = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr_fe, weight_decay=weight_decay)\n",
    "    for epoch in range(1, config[\"num_epochs_feature_extraction\"] + 1):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer_fe, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        history.append({\n",
    "            \"stage\": \"feature_extraction\",\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": float(train_loss),\n",
    "            \"train_acc\": float(train_acc),\n",
    "            \"val_loss\": float(val_loss),\n",
    "            \"val_acc\": float(val_acc),\n",
    "        })\n",
    "\n",
    "    # Tahap 2: Fine-tuning (opsional membuka layer backbone).\n",
    "    fine_tune_epochs = config.get(\"num_epochs_fine_tuning\", 0)\n",
    "    if fine_tune_epochs > 0:\n",
    "        set_feature_extractor_grad(model.feature_extractor, freeze_until=config.get(\"freeze_until\", \"all\"))\n",
    "        optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr_ft, weight_decay=weight_decay)\n",
    "        for epoch in range(1, fine_tune_epochs + 1):\n",
    "            train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer_ft, device)\n",
    "            val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "            history.append({\n",
    "                \"stage\": \"fine_tuning\",\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": float(train_loss),\n",
    "                \"train_acc\": float(train_acc),\n",
    "                \"val_loss\": float(val_loss),\n",
    "                \"val_acc\": float(val_acc),\n",
    "            })\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "history = run_training_cycles(model, datamodule, config, device)\n",
    "print(f\"Selesai training demo dengan {len(history)} entry riwayat.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca485dab",
   "metadata": {},
   "source": [
    "## I. Plot & Logging (Code)\n",
    "\n",
    "Visualisasi metrik dummy dan simpan artefak (plot serta ringkasan JSON) ke folder `outputs/` agar mudah diperiksa setelah praktikum.\n",
    "\n",
    "**Langkah Observasi**\n",
    "- Bandingkan kurva loss antar tahap; tuliskan observasi di jurnal belajar.\n",
    "- Screenshot tabel `history_df` atau catat angka penting (misal stagnasi akurasi) sebagai bahan diskusi.\n",
    "- Buka file JSON atau figur di `outputs/` lalu verifikasi penamaan file sesuai standar tim.\n",
    "\n",
    "Gunakan analogi latihan fisik: grafik loss adalah detak jantungmu. Saat mulai “berlari” (fine-tune), apakah detak meningkat (loss naik) sebelum turun stabil? Catat interpretasimu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d817743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feature_extraction</td>\n",
       "      <td>1</td>\n",
       "      <td>0.716024</td>\n",
       "      <td>0.62500</td>\n",
       "      <td>0.690948</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fine_tuning</td>\n",
       "      <td>1</td>\n",
       "      <td>0.673880</td>\n",
       "      <td>0.46875</td>\n",
       "      <td>0.684022</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                stage  epoch  train_loss  train_acc  val_loss  val_acc\n",
       "0  feature_extraction      1    0.716024    0.62500  0.690948    0.625\n",
       "1         fine_tuning      1    0.673880    0.46875  0.684022    0.500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot tersimpan di: /home/juni/Praktikum/deep-learning/transfer-learning-practicum/outputs/figures/loss_accuracy_demo.png\n",
      "Ringkasan run tersimpan di: /home/juni/Praktikum/deep-learning/transfer-learning-practicum/outputs/reports/run_summary.json\n",
      "Model checkpoint dummy tersimpan di: /home/juni/Praktikum/deep-learning/transfer-learning-practicum/models/demo_model_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "# Menyusun history ke DataFrame untuk analisis cepat.\n",
    "history_df = pd.DataFrame(history)\n",
    "if not history_df.empty:\n",
    "    display(history_df)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    for stage in history_df[\"stage\"].unique():\n",
    "        subset = history_df[history_df[\"stage\"] == stage]\n",
    "        axes[0].plot(subset[\"epoch\"], subset[\"train_loss\"], marker=\"o\", label=f\"{stage} train\")\n",
    "        axes[0].plot(subset[\"epoch\"], subset[\"val_loss\"], marker=\"s\", label=f\"{stage} val\")\n",
    "        axes[1].plot(subset[\"epoch\"], subset[\"train_acc\"], marker=\"o\", label=f\"{stage} train\")\n",
    "        axes[1].plot(subset[\"epoch\"], subset[\"val_acc\"], marker=\"s\", label=f\"{stage} val\")\n",
    "    axes[0].set_title(\"Loss per Stage\")\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].legend()\n",
    "    axes[1].set_title(\"Accuracy per Stage\")\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].set_ylabel(\"Accuracy\")\n",
    "    axes[1].legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig_path = project_root / config[\"fig_dir\"] / \"loss_accuracy_demo.png\"\n",
    "    fig.savefig(fig_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"Plot tersimpan di: {fig_path}\")\n",
    "else:\n",
    "    print(\"History kosong: tidak ada data untuk divisualisasikan.\")\n",
    "\n",
    "summary = {\n",
    "    \"device\": str(device),\n",
    "    \"config\": config,\n",
    "    \"history\": history,\n",
    "}\n",
    "summary_path = project_root / config[\"log_dir\"] / \"run_summary.json\"\n",
    "with summary_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(f\"Ringkasan run tersimpan di: {summary_path}\")\n",
    "\n",
    "model_path = project_root / config[\"save_dir\"] / \"demo_model_state_dict.pt\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model checkpoint dummy tersimpan di: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a6b836",
   "metadata": {},
   "source": [
    "## J. Ringkasan & Diskusi\n",
    "\n",
    "| Mode | Kecepatan | Kebutuhan Data | Risiko Overfitting | Kapan Dipilih |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Feature Extraction (Freeze) | Cepat (hanya train head) | Rendah | Rendah | Dataset kecil, domain mirip |\n",
    "| Fine-Tuning Parsial | Sedang (beberapa layer dibuka) | Menengah | Menengah | Saat butuh adaptasi moderat, layer akhir di-unfreeze |\n",
    "| Fine-Tuning Penuh | Paling lama | Tinggi | Lebih tinggi | Domain sangat berbeda, data cukup |\n",
    "\n",
    "**Pertanyaan Refleksi**\n",
    "- Jika analogi berjalan → jogging → sprint kamu terapkan, kapan kamu merasa siap naik tingkat dan mengapa?\n",
    "- Bagaimana mempersiapkan data tambahan (mis. augmentasi) agar transisi “lari” lebih stabil?\n",
    "- Jika performa tidak meningkat setelah fine-tuning, langkah diagnostik apa yang akan kamu coba terlebih dahulu?\n",
    "\n",
    "Gunakan jawabanmu sebagai bahan diskusi dengan teman kelas atau sebagai bagian dari laporan praktikum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26fb0f2",
   "metadata": {},
   "source": [
    "## K. Checklist Pemahaman\n",
    "\n",
    "Gunakan daftar berikut untuk mengecek pemahamanmu sebelum lanjut ke materi berikutnya.\n",
    "\n",
    "- [ ] Kamu dapat menjelaskan definisi dan manfaat transfer learning dengan bahasamu sendiri.\n",
    "- [ ] Kamu bisa membedakan freeze vs fine-tune beserta implikasi jumlah parameter yang dilatih.\n",
    "- [ ] Kamu tahu cara mengubah konfigurasi `freeze_until` serta menjelaskan dampaknya.\n",
    "- [ ] Kamu menemukan lokasi file output (`outputs/figures` dan `outputs/reports`) dan memahami isinya.\n",
    "- [ ] Kamu mampu menyebutkan minimal satu ide penerapan transfer learning pada bidang studi masing-masing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0217280",
   "metadata": {},
   "source": [
    "## L. Referensi\n",
    "\n",
    "- Slide: **Deep Learning 06 — Transfer Learning (Tatap Muka)** — ringkasan definisi, manfaat, jenis-jenis, serta strategi fine-tuning vs freeze yang digunakan dalam praktikum ini.\n",
    "- Buku: *Deep Learning* (Goodfellow et al.) Bab 15 mengenai representasi dan transfer.\n",
    "- Artikel: Pan dan Yang (2010) *A Survey on Transfer Learning* untuk memberikan landasan teori lebih formal.\n",
    "- Dokumentasi PyTorch Transfer Learning Tutorial — contoh resmi yang dapat dijadikan bacaan tambahan mahasiswa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f289c45f",
   "metadata": {},
   "source": [
    "## M. Panduan Langkah Transfer Learning\n",
    "\n",
    "Gunakan tahapan berikut sebagai rambu sederhana saat menerapkan transfer learning dari ImageNet ke Pascal VOC2007. Fokuslah pada konsep; kita menjaga beban komputasi tetap ringan.\n",
    "\n",
    "1. **Pilih backbone pretrained ImageNet.** Contoh: `torchvision.models.resnet18(weights=\"IMAGENET1K_V1\")`. Model ini sudah memahami bentuk umum seperti tepi, tekstur, dan pola objek.\n",
    "2. **Siapkan dataset target ringan.** VOC2007 dapat dimuat dengan subset kecil atau hanya beberapa kelas. Gunakan transformasi yang menyamakan ukuran dan normalisasi ke standar ImageNet.\n",
    "3. **Ganti classifier head.** Sesuaikan jumlah output dengan label VOC2007 (misal 20 kelas). Pada tahap ini kamu ibarat pemain biola yang mengganti skor musik menjadi pseudocode sementara ritme tetap sama.\n",
    "4. **Beku-kan layer awal.** Mulailah dengan mode feature extraction: matikan grad pada sebagian besar backbone sehingga hanya head yang belajar. Ini seperti berjalan santai sambil memegang biola, memindahkan rasa ritme ke latihan mengetik.\n",
    "5. **Latih dengan epoch singkat.** Gunakan batch kecil dan 3–5 epoch terlebih dahulu. Observasi loss dan akurasi; catat apa yang berubah.\n",
    "6. **Buka beberapa layer akhir bila diperlukan.** Jika performa stagnan, buka blok terakhir dan turunkan learning rate. Kini kamu beralih dari berjalan ke jogging, memadukan intuisi musikal dengan logika algoritmik.\n",
    "7. **Evaluasi dan catat insight.** Fokus pada apa yang kamu pelajari mengenai representasi fitur, bukan sekadar angka. Tanyakan: bagian mana yang paling banyak mentransfer pengetahuan?\n",
    "\n",
    "Iterasikan langkah-langkah ini secara bertahap; setiap siklus bagaikan mencoba genre musik baru sambil tetap membawa dasar teknik yang sama.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dcdf87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogi Transfer Learning:\n",
      "- Dari main biola ke ngoding: teknik mengenali pola irama dialihkan jadi "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logika if-else dan loop.\n",
      "- Dari berjalan santai ke sprint: mulai dengan freeze yang aman, lanjutkan fine-tune saat siap berlari.\n",
      "- Dari belajar bahasa serumpun ke bahasa baru: gunakan kosakata lama sebagai batu loncatan.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat <<'EOF'\n",
    "Analogi Transfer Learning:\n",
    "- Dari main biola ke ngoding: teknik mengenali pola irama dialihkan jadi logika if-else dan loop.\n",
    "- Dari berjalan santai ke sprint: mulai dengan freeze yang aman, lanjutkan fine-tune saat siap berlari.\n",
    "- Dari belajar bahasa serumpun ke bahasa baru: gunakan kosakata lama sebagai batu loncatan.\n",
    "EOF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ccafc",
   "metadata": {},
   "source": [
    "## N. Glosarium & Istilah Kunci\n",
    "\n",
    "- **Transfer Learning:** Teknik memanfaatkan model terlatih pada tugas berbeda sebagai titik awal tugas baru.\n",
    "- **Backbone:** Bagian utama jaringan (biasanya konvolusional) yang mengekstraksi fitur dari input.\n",
    "- **Classifier Head:** Lapisan akhir yang mengubah fitur menjadi prediksi kelas.\n",
    "- **Fine-Tuning:** Proses melatih ulang (sebagian) bobot pretrained agar menyesuaikan domain target.\n",
    "- **Freeze:** Menonaktifkan update grad pada layer tertentu.\n",
    "- **Feature Extraction:** Strategi menggunakan backbone beku untuk mengambil fitur lalu melatih classifier baru.\n",
    "- **Domain Gap:** Perbedaan karakteristik antara data sumber dan target; makin lebar gap, makin banyak adaptasi diperlukan.\n",
    "- **Early Stopping:** Teknik menghentikan training saat validasi tidak membaik untuk mencegah overfitting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
